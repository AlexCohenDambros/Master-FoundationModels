{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Description\n",
    "\n",
    "This code prepares the model's training datasets. The output format is JSON Lines (jsonl), ideal for training models with large datasets, while keeping the data structure lightweight and easy to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../database/combined_data.csv', sep=\";\")\n",
    "\n",
    "state_product_dict = {\n",
    "    state: list(all_data[all_data['state'] == state]['product'].unique())\n",
    "    for state in all_data['state'].unique()\n",
    "}\n",
    "\n",
    "output_file = 'dataset_global/dataset_global.jsonl'\n",
    "\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file, 'w') as file:\n",
    "\n",
    "    ''' \n",
    "    # INFO: ======== Remove SP ========\n",
    "    ''' \n",
    "    for state, products in state_product_dict.items():\n",
    "        if state == \"sp\":\n",
    "            continue\n",
    "\n",
    "        for product in products:\n",
    "            \n",
    "            # Filter data for the current state and product\n",
    "            data_filtered = all_data[(all_data['state'] == state) & (all_data['product'] == product)]\n",
    "\n",
    "            sequence = data_filtered['m3'].tolist()\n",
    "            json_line = {f'{product}_{state}': sequence}\n",
    "\n",
    "            file.write(json.dumps(json_line) + '\\n')\n",
    "    \n",
    "    # ''' \n",
    "    # # INFO: ======== Raw Data ========\n",
    "    # ''' \n",
    "    # for state, products in state_product_dict.items():\n",
    "    #     for product in products:\n",
    "\n",
    "    #         # Filter data for the current state and product\n",
    "    #         data_filtered = all_data[(all_data['state'] == state) & (all_data['product'] == product)]\n",
    "\n",
    "    #         sequence = data_filtered['m3'].tolist()\n",
    "    #         json_line = {f'{product}_{state}': sequence}\n",
    "\n",
    "    #         file.write(json.dumps(json_line) + '\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    # INFO: ======== MinMaxScaler ========\n",
    "    ''' \n",
    "    # for state, products in state_product_dict.items():\n",
    "    #     for product in products:\n",
    "    #         data_filtered = all_data[(all_data['state'] == state) & (all_data['product'] == product)]\n",
    "            \n",
    "    #         data = rolling_window(data_filtered['m3'], 12)\n",
    "    #         print(data)\n",
    "\n",
    "    #         sequence = data.values  \n",
    "\n",
    "    #         print(sequence)\n",
    "            \n",
    "    #         scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    #         sequence_scaled = scaler.fit_transform(sequence.reshape(-1, 1)).flatten()\n",
    "    #         print(sequence_scaled)\n",
    "            \n",
    "    #         json_line = {\"sequence\": sequence_scaled.tolist()} \n",
    "            \n",
    "    #         file.write(json.dumps(json_line) + '\\n')\n",
    "    \n",
    "\n",
    "print(f\"Filtered data has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../database/combined_data.csv', sep=';')\n",
    "\n",
    "states = all_data['state'].unique()\n",
    "\n",
    "for excluded_state in states:\n",
    "    data_filtered_all = all_data[all_data['state'] != excluded_state]\n",
    "\n",
    "    state_product_dict = {\n",
    "        state: list(data_filtered_all[data_filtered_all['state'] == state]['product'].unique())\n",
    "        for state in data_filtered_all['state'].unique()\n",
    "    }\n",
    "\n",
    "    output_file = f'all_datasets_global/dataset_{excluded_state}.jsonl'\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        for state, products in state_product_dict.items():\n",
    "            for product in products:\n",
    "                data_filtered = data_filtered_all[(data_filtered_all['state'] == state) & (data_filtered_all['product'] == product)]\n",
    "                sequence = data_filtered['m3'].tolist()\n",
    "                json_line = {f'sequence': sequence}\n",
    "                file.write(json.dumps(json_line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets global 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset criado: all_datasets_global_by_years/excluding_pe\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pe\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pe\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pe\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pe\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ba\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ba\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ba\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ba\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ba\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ro\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ro\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ro\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ro\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ro\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_es\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_es\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_es\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_es\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_es\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pi\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pi\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pi\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pi\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pi\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_to\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_to\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_to\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_to\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_to\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ma\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ma\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ma\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ma\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ma\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pr\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pr\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pr\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pr\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pr\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ap\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ap\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ap\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ap\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ap\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sc\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sc\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sc\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sc\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sc\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mt\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mt\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mt\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mt\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mt\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rs\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rs\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rs\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rs\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rs\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rr\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rr\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rr\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rr\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rr\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rn\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rn\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rn\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rn\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rn\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rj\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rj\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rj\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rj\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_rj\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_df\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_df\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_df\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_df\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_df\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pb\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pb\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pb\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pb\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pb\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ms\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ms\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ms\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ms\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ms\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sp\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sp\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sp\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sp\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_sp\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mg\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mg\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mg\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mg\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_mg\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_al\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_al\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_al\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_al\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_al\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_se\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_se\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_se\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_se\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_se\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ac\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ac\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ac\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ac\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ac\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pa\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pa\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pa\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pa\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_pa\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_am\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_am\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_am\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_am\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_am\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_go\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_go\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_go\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_go\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_go\\dataset_2020.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ce\\dataset_2024.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ce\\dataset_2023.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ce\\dataset_2022.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ce\\dataset_2021.jsonl\n",
      "Dataset criado: all_datasets_global_by_years/excluding_ce\\dataset_2020.jsonl\n",
      "Todos os datasets foram gerados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# 1. Carregar os dados\n",
    "# ==========================\n",
    "all_data = pd.read_csv('../database/combined_data.csv', sep=';')\n",
    "all_data['timestamp'] = pd.to_datetime(all_data['timestamp'], errors='coerce')\n",
    "\n",
    "# ==========================\n",
    "# 2. Configurações de saída\n",
    "# ==========================\n",
    "base_output_path = 'all_datasets_global_by_years/'\n",
    "os.makedirs(base_output_path, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# 3. Iterar sobre estados excluídos\n",
    "# ==========================\n",
    "states = all_data['state'].unique()\n",
    "end_date = all_data['timestamp'].max()\n",
    "\n",
    "for excluded_state in states:\n",
    "    # Filtrar os dados removendo o estado excluído\n",
    "    data_filtered_all = all_data[all_data['state'] != excluded_state]\n",
    "\n",
    "    # Criar pasta para cada estado excluído\n",
    "    excluded_state_path = os.path.join(base_output_path, f'excluding_{excluded_state}')\n",
    "    os.makedirs(excluded_state_path, exist_ok=True)\n",
    "\n",
    "    # ==========================\n",
    "    # 4. Iterar sobre janelas de anos (5 -> 1)\n",
    "    # ==========================\n",
    "    for years in range(5, 0, -1):\n",
    "        yearly_data = data_filtered_all[\n",
    "            data_filtered_all['timestamp'] <= end_date - pd.DateOffset(years=(5 - years))\n",
    "        ]\n",
    "\n",
    "        # Nome do arquivo para este conjunto\n",
    "        output_file = os.path.join(\n",
    "            excluded_state_path,\n",
    "            f'dataset_{(end_date - pd.DateOffset(years=(5 - years))).year}.jsonl'\n",
    "        )\n",
    "\n",
    "        # ==========================\n",
    "        # 5. Gerar datasets por estado e produto\n",
    "        # ==========================\n",
    "        with open(output_file, 'w') as file:\n",
    "            for state in yearly_data['state'].unique():\n",
    "                products = yearly_data[yearly_data['state'] == state]['product'].unique()\n",
    "\n",
    "                for product in products:\n",
    "                    data_filtered = yearly_data[\n",
    "                        (yearly_data['state'] == state) &\n",
    "                        (yearly_data['product'] == product)\n",
    "                    ]\n",
    "\n",
    "                    sequence = data_filtered['m3'].tolist()\n",
    "\n",
    "                    if sequence:\n",
    "                        json_line = {'sequence': sequence}\n",
    "                        file.write(json.dumps(json_line) + '\\n')\n",
    "\n",
    "        print(f\"Dataset criado: {output_file}\")\n",
    "\n",
    "print(\"Todos os datasets foram gerados com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

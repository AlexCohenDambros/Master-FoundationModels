{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/rapids-24.06/lib/python3.11/site-packages/optuna/study/_optimize.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from optuna import progress_bar as pbar_module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PyTorch TimesFM, likely because python version is 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0].\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from model_moe.time_moe.experts.timesfm_expert import TimesFMExpert\n",
    "from model_moe.time_moe.experts.timemoe_expert import TimeMoEExpert\n",
    "from model_moe.time_moe.experts.moirai_expert import MoiraiMoEExpert\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3956,  0.5525,  0.1551,  0.0066, -1.5103,  0.4508,  0.0104,  0.1302,\n",
      "          2.2411, -0.5683,  0.5041, -0.4484, -0.6131,  1.5338,  1.1665,  0.8377,\n",
      "          1.2702, -0.2789,  0.3790, -1.1013, -0.5424,  0.9069, -1.0729, -0.6536,\n",
      "          1.0879, -1.0092,  2.1214, -0.1206, -1.5171, -1.2537, -0.2177, -0.1600,\n",
      "         -1.3607, -1.1176, -0.4977, -1.0659,  1.2051, -0.3588, -0.6960,  0.0166,\n",
      "         -0.6978,  1.6835, -0.2299,  0.1126, -0.0320,  0.1819, -1.0597, -1.9144,\n",
      "         -0.0333,  2.1827, -0.3528,  0.3871,  0.4657, -0.3634, -0.1209, -0.0653,\n",
      "          0.3820,  0.5238, -0.4789,  0.8483,  0.2721,  0.0672, -0.3439,  0.1487,\n",
      "          1.6102, -0.0420,  1.8382,  1.4088, -1.5758, -0.9502, -1.2504,  0.6930,\n",
      "          0.3333,  1.3676,  1.1131, -0.8537,  0.1726,  0.7429, -0.9829, -2.2182,\n",
      "         -0.9030,  0.4981,  0.9149,  0.4870,  1.1158, -0.6794,  1.6060, -1.4343,\n",
      "         -0.1103,  1.3372,  0.1923, -0.7722, -1.2655,  0.2587,  0.2938, -1.3925,\n",
      "         -1.4604,  1.1553, -0.5986,  0.5688, -1.1308,  0.2737, -0.6758,  0.4241,\n",
      "         -0.1635,  1.4049, -0.1817, -0.9106,  0.6926,  1.9486, -0.8175,  0.8462,\n",
      "          0.9931,  1.7106,  0.3715,  1.1974,  0.4209, -1.4072, -0.7793,  0.0491,\n",
      "         -0.1899,  1.1714, -1.7841,  1.7211,  0.4805, -0.5900,  0.5096,  0.7824]])\n"
     ]
    }
   ],
   "source": [
    "context_length = 128\n",
    "prediction_length = 32\n",
    "\n",
    "# Criar input adequado - ex: (batch_size, seq_len)\n",
    "seqs = torch.randn(1, context_length)\n",
    "\n",
    "print(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimeMoEExpert ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/rapids-24.06/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda3/envs/rapids-24.06/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-MoE\n",
      "tensor([[ 0.5174, -0.1247, -0.3909, -0.0346, -0.4093,  0.0250, -0.0579,  0.0538,\n",
      "         -0.5604, -1.1265, -0.4702, -0.2858, -0.7341, -0.2922, -0.3737, -0.1966,\n",
      "          0.0493, -0.0096, -0.2893, -0.5106, -0.1505,  0.3801,  0.1007,  0.3337,\n",
      "          0.1468,  0.0306,  0.1091,  0.0837,  0.2882,  0.3808,  0.0478, -0.0404]])\n",
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TimeMoEExpert ===\")\n",
    "timemoe = TimeMoEExpert(prediction_length, device=\"cpu\")\n",
    "out2 = timemoe.forward(seqs)\n",
    "print(out2)\n",
    "print(out2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TimesFMExpert ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 117159.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesFM\n",
      "tensor([[ 0.1257,  0.1086,  0.0403,  0.0207,  0.1241,  0.2579,  0.2372,  0.2131,\n",
      "          0.1769,  0.1391,  0.0181,  0.0935,  0.1205,  0.1109,  0.0556,  0.0363,\n",
      "          0.0163,  0.0013,  0.0737,  0.1711,  0.1389,  0.0819,  0.0385,  0.0018,\n",
      "         -0.0514,  0.0734,  0.1639,  0.1702,  0.1460,  0.1297,  0.0664,  0.0439]])\n",
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TimesFMExpert ===\")\n",
    "timesfm_expert = TimesFMExpert(prediction_length, device=\"cuda\")\n",
    "out_timesfm = timesfm_expert.forward(seqs)\n",
    "print(out_timesfm)\n",
    "print(out_timesfm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MoiraiMoEExpert ===\n",
      "MoiraiMoE\n",
      "tensor([[ 2.5226,  0.1483,  1.4191,  4.0782, -1.3317, -0.5861,  0.0778,  1.0835,\n",
      "          1.9446,  1.2338,  0.2294,  0.8178,  3.2166,  0.6526,  1.3257,  2.0676,\n",
      "         -0.4659,  2.7316,  2.7146,  1.2093,  0.1106,  2.4888,  0.9620,  0.3818,\n",
      "          5.6913,  0.8332,  1.3742,  0.8813,  1.1638,  0.4807,  0.0778,  1.8887]])\n",
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MoiraiMoEExpert ===\")\n",
    "cufedido = MoiraiMoEExpert(prediction_length, device=\"cuda\")\n",
    "out_timesfm2 = cufedido.forward(seqs)\n",
    "print(out_timesfm2)\n",
    "print(out_timesfm2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
